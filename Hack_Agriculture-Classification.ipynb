{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T12:16:16.577071Z","iopub.status.busy":"2024-08-24T12:16:16.576611Z","iopub.status.idle":"2024-08-24T12:16:16.587145Z","shell.execute_reply":"2024-08-24T12:16:16.585975Z","shell.execute_reply.started":"2024-08-24T12:16:16.577018Z"},"trusted":true},"outputs":[],"source":["class_map = {'Apple___Apple_scab': 0, 'Apple___Black_rot': 1, 'Apple___Cedar_apple_rust': 2, 'Apple___healthy': 3,\n","             'Corn___Cercospora_leaf_spot Gray_leaf_spot': 4, 'Corn___Common_rust': 5, 'Corn___Northern_Leaf_Blight': 6, 'Corn___healthy': 7,\n","             'Durian___Algal_Leaf_Spot': 8, 'Durian___Leaf_Blight': 9, 'Durian___Leaf_Spot': 10, 'Durian___healthy': 11,\n","             'Grape___Black_rot': 12, 'Grape___Esca_(Black_Measles)': 13, 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 14, 'Grape___healthy': 15,\n","             'OilPalm___brown_spots': 16, 'OilPalm___healthy': 17, 'OilPalm___white_scale': 18,\n","             'Orange___Haunglongbing_(Citrus_greening)': 19,\n","             'Pepper_bell___Bacterial_spot': 20, 'Pepper_bell___healthy': 21,\n","             'Potato___Early_blight': 22, 'Potato___Late_blight': 23, 'Potato___healthy': 24,\n","             'Rice___Bacterialblight': 25, 'Rice___Blast': 26, 'Rice___Brownspot': 27, 'Rice___Tungro': 28,\n","             'Soybean___healthy': 29,\n","             'Strawberry___Leaf_scorch': 30, 'Strawberry___healthy': 31,\n","             'Tomato___Bacterial_spot': 32, 'Tomato___Early_blight': 33, 'Tomato___Late_blight': 34, 'Tomato___Leaf_Mold': 35, 'Tomato___Septoria_leaf_spot': 36, 'Tomato___Spider_mites Two-spotted_spider_mite': 37, 'Tomato___Target_Spot': 38, 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 39, 'Tomato___Tomato_mosaic_virus': 40, 'Tomato___healthy': 41}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T12:16:16.589574Z","iopub.status.busy":"2024-08-24T12:16:16.589018Z","iopub.status.idle":"2024-08-24T12:16:17.382949Z","shell.execute_reply":"2024-08-24T12:16:17.381885Z","shell.execute_reply.started":"2024-08-24T12:16:16.589529Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","df = pd.read_csv(\"/kaggle/input/hackathon-online-agriculture-classification/train.csv\")\n","\n","reverse_class_map = {v: k for k, v in class_map.items()}\n","df['full_label'] = df['label'].map(reverse_class_map)\n","\n","df['parent_label'] = df['full_label'].str.split('___').str[0]\n","\n","df['parent_label'] = df['parent_label'].astype('category').cat.codes\n","\n","display(df)\n","    \n","df.to_csv(\"updated_train.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-08-24T12:16:17.384635Z","iopub.status.busy":"2024-08-24T12:16:17.384256Z","iopub.status.idle":"2024-08-24T12:16:17.393325Z","shell.execute_reply":"2024-08-24T12:16:17.392237Z","shell.execute_reply.started":"2024-08-24T12:16:17.384591Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","import os\n","\n","class ImageClassificationDataset(Dataset):\n","    def __init__(self, csv_file, img_dir, transform=None):\n","        self.annotations = pd.read_csv(csv_file)\n","        self.img_dir = img_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.annotations)\n","\n","    def __getitem__(self, index):\n","        img_id = self.annotations.iloc[index, 0]\n","        img_path = os.path.join(self.img_dir, f\"{img_id}.jpg\")\n","        image = Image.open(img_path).convert(\"RGB\")\n","        label = int(self.annotations.iloc[index, 1])\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T12:16:17.396649Z","iopub.status.busy":"2024-08-24T12:16:17.396293Z","iopub.status.idle":"2024-08-24T12:16:17.406740Z","shell.execute_reply":"2024-08-24T12:16:17.405701Z","shell.execute_reply.started":"2024-08-24T12:16:17.396606Z"},"trusted":true},"outputs":[],"source":["class HierarchicalImageClassificationDataset(Dataset):\n","    def __init__(self, csv_file, img_dir, transform=None):\n","        self.annotations = pd.read_csv(csv_file)\n","        self.img_dir = img_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.annotations)\n","\n","    def __getitem__(self, index):\n","        # Read image ID using column name\n","        img_id = self.annotations.loc[index, 'id']\n","        img_path = os.path.join(self.img_dir, f\"{img_id}.jpg\")\n","        \n","        # Load image\n","        image = Image.open(img_path).convert(\"RGB\")\n","        \n","        # Read parent class label and subclass label using column names\n","        parent_label = int(self.annotations.loc[index, 'parent_label'])\n","        subclass_label = int(self.annotations.loc[index, 'label'])\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, (parent_label, subclass_label)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T12:16:17.410274Z","iopub.status.busy":"2024-08-24T12:16:17.409999Z","iopub.status.idle":"2024-08-24T12:16:17.515528Z","shell.execute_reply":"2024-08-24T12:16:17.514315Z","shell.execute_reply.started":"2024-08-24T12:16:17.410245Z"},"trusted":true},"outputs":[],"source":["from torchvision import transforms\n","from torch.utils.data import DataLoader, random_split\n","from sklearn.model_selection import StratifiedKFold\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomResizedCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","img_dir = \"/kaggle/input/hackathon-online-agriculture-classification/Images\"\n","train_csv = \"/kaggle/working/updated_train.csv\"\n","dataset = HierarchicalImageClassificationDataset(csv_file=train_csv, img_dir=img_dir, transform=transform)\n","\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T12:16:17.519445Z","iopub.status.busy":"2024-08-24T12:16:17.517899Z","iopub.status.idle":"2024-08-24T12:16:17.574995Z","shell.execute_reply":"2024-08-24T12:16:17.573919Z","shell.execute_reply.started":"2024-08-24T12:16:17.519402Z"},"trusted":true},"outputs":[],"source":["class TestDataset(Dataset):\n","    def __init__(self, csv_file, img_dir, transform=None):\n","        self.annotations = pd.read_csv(csv_file)\n","        self.img_dir = img_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.annotations)\n","\n","    def __getitem__(self, index):\n","        img_id = self.annotations.iloc[index, 0]\n","        img_path = os.path.join(self.img_dir, f\"{img_id}.jpg\")\n","        image = Image.open(img_path).convert(\"RGB\")\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, img_id\n","\n","# Load the test dataset\n","test_csv = \"/kaggle/input/hackathon-online-agriculture-classification/test.csv\"\n","test_dataset = TestDataset(csv_file=test_csv, img_dir=img_dir, transform=transform)\n","\n","# Create DataLoader for test set\n","test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T12:16:17.577341Z","iopub.status.busy":"2024-08-24T12:16:17.576635Z","iopub.status.idle":"2024-08-24T12:16:19.862653Z","shell.execute_reply":"2024-08-24T12:16:19.861711Z","shell.execute_reply.started":"2024-08-24T12:16:17.577295Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import timm\n","from torchvision import models\n","from tqdm.auto import tqdm\n","\n","# model = models.resnet18()\n","# model.fc = nn.Linear(model.fc.in_features, num_classes) \n","\n","class ResNet18Hierarchical(nn.Module):\n","    def __init__(self, num_parent_classes, num_subclasses):\n","        super(ResNet18Hierarchical, self).__init__()\n","        \n","        # Load the pre-trained ResNet18 model\n","        self.resnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n","        \n","        # Capture the number of features in the original fully connected layer\n","        num_features = self.resnet.fc.in_features\n","        \n","        # Replace the original fully connected layer with an Identity layer\n","        self.resnet.fc = nn.Identity()\n","        \n","        # New fully connected layers for parent class and subclass\n","        self.fc_parent = nn.Linear(num_features, num_parent_classes)\n","        self.fc_subclass = nn.Linear(num_features, num_subclasses)\n","    \n","    def forward(self, x):\n","        # Extract features using the pre-trained ResNet18 model\n","        x = self.resnet(x)\n","        \n","        # Classify into parent class and subclass\n","        parent_class_logits = self.fc_parent(x)\n","        subclass_logits = self.fc_subclass(x)\n","        \n","        return parent_class_logits, subclass_logits\n","\n","class ViTHierarchical(nn.Module):\n","    def __init__(self, num_parent_classes, num_subclasses):\n","        super(ViTHierarchical, self).__init__()\n","        # Load a pre-trained Vision Transformer model\n","        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True)\n","        \n","        # Replace the classifier head with Identity to get the feature vector\n","        self.vit.head = nn.Identity()\n","        \n","        # Define separate fully connected layers for parent class and subclass\n","        self.fc_parent = nn.Linear(self.vit.num_features, num_parent_classes)\n","        self.fc_subclass = nn.Linear(self.vit.num_features, num_subclasses)\n","    \n","    def forward(self, x):\n","        # Extract features from the pre-trained Vision Transformer\n","        x = self.vit(x)\n","        \n","        # Classify into parent class and subclass\n","        parent_class_logits = self.fc_parent(x)\n","        subclass_logits = self.fc_subclass(x)\n","        \n","        return parent_class_logits, subclass_logits\n","    \n","num_parent_classes = 12\n","num_subclasses = 42\n","# model = ResNet18Hierarchical(num_parent_classes, num_subclasses)\n","model = ViTHierarchical(num_parent_classes, num_subclasses)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","if torch.cuda.device_count() > 1:\n","    print(f\"Using {torch.cuda.device_count()} GPUs for training.\")\n","    model = nn.DataParallel(model)\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T12:16:19.865244Z","iopub.status.busy":"2024-08-24T12:16:19.864164Z","iopub.status.idle":"2024-08-24T13:21:17.654061Z","shell.execute_reply":"2024-08-24T13:21:17.652908Z","shell.execute_reply.started":"2024-08-24T12:16:19.865197Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import f1_score\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","num_epochs = 20\n","\n","best_val_f1 = 0.0\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    for images, (parent_labels, subclass_labels) in tqdm(train_loader):\n","        images = images.to(device)\n","        parent_labels = parent_labels.to(device)\n","        subclass_labels = subclass_labels.to(device)\n","        \n","        optimizer.zero_grad()\n","        \n","        parent_logits, subclass_logits = model(images)\n","\n","        loss_parent = criterion(parent_logits, parent_labels)\n","        loss_subclass = criterion(subclass_logits, subclass_labels)\n","\n","        loss = loss_parent + loss_subclass\n","\n","        loss.backward()\n","        optimizer.step()\n","        \n","    \n","    model.eval()\n","    val_loss = 0.0\n","    all_labels = []\n","    all_predictions = []\n","\n","    with torch.no_grad():\n","        for images, (parent_labels, subclass_labels) in val_loader:\n","            images, labels = images.to(device), subclass_labels.to(device)\n","            \n","            parent_logits, subclass_logits = model(images)\n","            \n","            loss = criterion(subclass_logits, labels)\n","            val_loss += loss.item()\n","\n","            _, predicted = torch.max(subclass_logits, 1)\n","            all_labels.extend(labels.cpu().numpy())\n","            all_predictions.extend(predicted.cpu().numpy())\n","\n","    val_loss /= len(val_loader)\n","    val_f1 = f1_score(all_labels, all_predictions, average='macro')\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n","          f\"Train Loss: {loss.item():.4f}, \"\n","          f\"Validation Loss: {val_loss:.4f}, \"\n","          f\"Validation F1 Macro: {val_f1:.4f}\")\n","\n","    if val_f1 > best_val_f1:\n","        best_val_f1 = val_f1\n","        torch.save(model.state_dict(), \"best_model.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-24T13:21:17.654912Z","iopub.status.idle":"2024-08-24T13:21:17.655271Z","shell.execute_reply":"2024-08-24T13:21:17.655115Z","shell.execute_reply.started":"2024-08-24T13:21:17.655097Z"},"trusted":true},"outputs":[],"source":["submit_df = pd.read_csv(\"/kaggle/input/hackathon-online-agriculture-classification/submit.csv\")\n","\n","model.eval()\n","\n","predictions = []\n","\n","with torch.no_grad():\n","    for images, img_ids in tqdm(test_loader):\n","        images = images.to(device)\n","        parent_logits, subclass_logits = model(images)\n","        _, predicted = torch.max(subclass_logits, 1)\n","        predictions.extend(predicted.cpu().numpy())\n","\n","submit_df['predict'] = predictions\n","\n","submit_df.to_csv(\"submission.csv\", index=False)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":9410943,"sourceId":84180,"sourceType":"competition"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}
